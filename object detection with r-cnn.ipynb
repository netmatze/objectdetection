{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b86385-11d9-49cc-8c4d-7cdbc9d67c86",
   "metadata": {},
   "source": [
    "## create a r-cnn model for object detection and train it with the Aquarium datase\n",
    "\n",
    "### https://public.roboflow.com/object-detection/aquarium/2#\n",
    "\n",
    "### https://chatgpt.com/c/5f97037a-3b6c-4521-bc2f-8070b6ee8b50\n",
    "\n",
    "## \"Aquarium.coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cae160b-30ab-44d7-ad25-c41e3698bf54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roboflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install roboflow\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mroboflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Roboflow\n\u001b[0;32m      4\u001b[0m rf \u001b[38;5;241m=\u001b[39m Roboflow(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfqSAzeINBX9oPfwLixDj\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m project \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mworkspace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrad-dwyer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mproject(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maquarium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"fqSAzeINBX9oPfwLixDj\")\n",
    "project = rf.workspace(\"brad-dwyer\").project(\"aquarium\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c39ffeb-329c-4ab5-85e8-cb3d9847d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381bacc-ded8-46dc-82f4-a65e47338d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348d9591-ef13-4452-9661-1fb1e2c3f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoboFlowDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"train\"))))\n",
    "        self.annotations = json.load(open(os.path.join(root, \"train/_annotations.coco.json\")))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"train\", self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        ann = [a for a in self.annotations['annotations'] if a['image_id'] == idx]\n",
    "        boxes = [a['bbox'] for a in ann]\n",
    "        labels = [a['category_id'] for a in ann]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c834636c-90fe-4859-a790-55ae37bfa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # [16, H/2, W/2]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # [16, H/4, W/4]\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # [32, H/8, W/8]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # [32, H/16, W/16]\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # [64, H/32, W/32]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # [64, H/64, W/64]\n",
    "        )\n",
    "        self.out_channels = 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57682197-ee2f-4e6d-ae7b-623728284831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(DetectionHead, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(in_channels * 7 * 7, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(in_channels * 7 * 7, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 4)  # 4 for bounding box regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        cls_logits = self.cls_head(x)\n",
    "        bbox_reg = self.reg_head(x)\n",
    "        return cls_logits, bbox_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc4c050-d979-43db-81a5-6a608516eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRCNN(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super(SimpleRCNN, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = DetectionHead(backbone.out_channels, num_classes)\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        features = self.backbone(images)\n",
    "        pooled_features = nn.functional.adaptive_max_pool2d(features, (7, 7))\n",
    "\n",
    "        cls_logits, bbox_reg = self.head(pooled_features)\n",
    "        \n",
    "        if self.training:\n",
    "            loss_cls = nn.CrossEntropyLoss()(cls_logits, targets[\"labels\"])\n",
    "            loss_bbox = nn.MSELoss()(bbox_reg, targets[\"boxes\"])\n",
    "            losses = {\"loss_cls\": loss_cls, \"loss_bbox\": loss_bbox}\n",
    "            return losses\n",
    "        \n",
    "        return cls_logits, bbox_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff172e91-9f82-47cd-bc16-1a0785a992ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleRCNN(\n",
       "  (backbone): SimpleCNN(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (head): DetectionHead(\n",
       "    (cls_head): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=9, bias=True)\n",
       "    )\n",
       "    (reg_head): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anzahl der Klassen im Roboflow-Dataset (einschließlich Hintergrund)\n",
    "num_classes = len(json.load(open('Aquarium.coco/train/_annotations.coco.json'))['categories']) + 1\n",
    "\n",
    "dataset = RoboFlowDataset('Aquarium.coco', get_transform(train=True))\n",
    "dataset_test = RoboFlowDataset('Aquarium.coco', get_transform(train=False))\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=2, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "backbone = SimpleCNN()\n",
    "model = SimpleRCNN(backbone, num_classes)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4302921-f628-472e-b796-7bb1fb3a34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 2 epochs\n"
     ]
    }
   ],
   "source": [
    "# Optimierer definieren\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training\n",
    "num_epochs = 2\n",
    "print(f\"Running for {num_epochs} epochs\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = torch.stack(images).to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        losses = model(images, targets)\n",
    "        loss = sum(loss for loss in losses.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += counter\n",
    "        if counter % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} - Run: {counter}\")\n",
    "    \n",
    "    # Lernrate anpassen\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50485ccd-ca49-4958-bc86-4f3f6edee97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"simple_rcnn.pth\")\n",
    "\n",
    "# Um das Modell später zu laden\n",
    "backbone = SimpleCNN()\n",
    "model = SimpleRCNN(backbone, num_classes)\n",
    "model.load_state_dict(torch.load(\"simple_rcnn.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2a454-b8c4-4e9e-b7db-145db76af7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Laden Sie das Modell\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "backbone = SimpleCNN()\n",
    "model = SimpleRCNN(backbone, num_classes)  # num_classes entspricht der Anzahl der Klassen in Ihrem Dataset\n",
    "model.load_state_dict(torch.load(\"simple_rcnn.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6bdae-481f-4a5b-99a0-c29616218e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)  # Fügen Sie eine Batch-Dimension hinzu\n",
    "    return image, image_tensor\n",
    "\n",
    "image_path = 'path_to_your_image.jpg'\n",
    "image, image_tensor = load_image(image_path)\n",
    "image_tensor = image_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c153616-e061-409a-bdfe-72cabbfcf31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cls_logits, bbox_reg = model(image_tensor)\n",
    "\n",
    "# Konvertieren Sie die Ergebnisse in numpy Arrays und bringen Sie sie auf die CPU\n",
    "cls_logits = cls_logits.cpu().numpy()\n",
    "bbox_reg = bbox_reg.cpu().numpy()\n",
    "\n",
    "# Wählen Sie die Klasse mit der höchsten Wahrscheinlichkeit\n",
    "predicted_class = np.argmax(cls_logits, axis=1)\n",
    "predicted_boxes = bbox_reg\n",
    "\n",
    "# Umwandeln der Bounding Box-Koordinaten\n",
    "predicted_boxes[:, 0] = predicted_boxes[:, 0] * image.width\n",
    "predicted_boxes[:, 1] = predicted_boxes[:, 1] * image.height\n",
    "predicted_boxes[:, 2] = predicted_boxes[:, 2] * image.width\n",
    "predicted_boxes[:, 3] = predicted_boxes[:, 3] * image.height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86deb58-9bb4-431a-91a2-ecac07005ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(image, boxes, labels):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for box, label in zip(boxes, labels):\n",
    "        # Zeichnen Sie die Bounding Box\n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2], box[3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        # Textbeschriftung hinzufügen\n",
    "        plt.text(box[0], box[1], f'Class: {label}', bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_results(image, predicted_boxes, predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42def8d8-bc57-4614-a42e-0680084190b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5238e58-cfff-40a2-be18-799988988792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378532b-cd45-418a-837a-292e4e20f769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927078ae-25ca-40a6-bbc3-268c93e5d369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
